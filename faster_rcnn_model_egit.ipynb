{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtive'a bağlan\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308351da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veriseti sınıfını oluştur\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transforms=None):\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            self.coco = json.load(f)\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco['images'])\n",
    "\n",
    "    # Modify the __getitem__ method in your CocoDataset class\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.coco['images'][idx]\n",
    "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        annotations = [\n",
    "            ann for ann in self.coco['annotations'] if ann['image_id'] == img_info['id']\n",
    "        ]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in annotations:\n",
    "            # COCO format is [x, y, width, height]\n",
    "            # Convert to [x_min, y_min, x_max, y_max] for PyTorch\n",
    "            x, y, width, height = ann['bbox']\n",
    "            boxes.append([x, y, x + width, y + height])\n",
    "            # Offset category_id by 1 to account for background class\n",
    "            labels.append(ann['category_id'] + 1)  # Adding +1 here\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "# Custom transform class that can handle both images and targets\n",
    "class CustomCompose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            if isinstance(t, torchvision.transforms.ToTensor):\n",
    "                image = t(image)\n",
    "            else:\n",
    "                image, target = t(image, target)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Verileri yükle\n",
    "train_dataset = CocoDataset(\n",
    "    annotations_file=\"faster_rcnn_dataset/annotations_train.json\",\n",
    "    img_dir=\"faster_rcnn_dataset/train\",\n",
    "    transforms=CustomCompose([ToTensor()])\n",
    ")\n",
    "\n",
    "def check_class_distribution(dataset):\n",
    "    class_counts = {}\n",
    "    for i in range(len(dataset)):\n",
    "        _, target = dataset[i]\n",
    "        labels = target[\"labels\"].tolist()\n",
    "        for label in labels:\n",
    "            if label not in class_counts:\n",
    "                class_counts[label] = 0\n",
    "            class_counts[label] += 1\n",
    "\n",
    "    print(\"Class distribution:\")\n",
    "    for class_id, count in sorted(class_counts.items()):\n",
    "        print(f\"Class {class_id}: {count} instances\")\n",
    "\n",
    "check_class_distribution(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Pretrained Faster R-CNN modelini yükle - Fix deprecation warning\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    ")\n",
    "\n",
    "# Sınıf sayısını değiştir (arka plan + sınıflar)\n",
    "num_classes = len(train_dataset.coco['categories']) + 1  # Background + sınıflar\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.coco['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeli eğit\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Cihaz seçimi\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Eğitim döngüsü\n",
    "num_epochs = 130\n",
    "epoch_losses = []  # Track losses for plotting\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, targets in tqdm(train_loader):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "    epoch_losses.append(epoch_loss)  # Store loss for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae50191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim grafiklerini çiz ve kaydet\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.utils import draw_bounding_boxes, make_grid\n",
    "\n",
    "# Loss grafiğini çiz\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), epoch_losses, marker='o')\n",
    "plt.title('Eğitim Kaybı Değişimi')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig('training_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Örnek tahminler için modeli değerlendirme moduna al\n",
    "model.eval()\n",
    "\n",
    "# Birkaç örnek görüntü üzerinde tahminleri görselleştir\n",
    "num_samples = min(5, len(train_dataset))\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(15, num_samples*3))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        # Veri setinden bir örnek al\n",
    "        img, target = train_dataset[i]\n",
    "\n",
    "        # Sol tarafta gerçek kutular ile görüntü\n",
    "        img_tensor = img.clone()\n",
    "        orig_boxes = target[\"boxes\"].cpu()\n",
    "        orig_labels = target[\"labels\"].cpu()\n",
    "\n",
    "        # Tahminleri alma\n",
    "        prediction = model([img.to(device)])[0]\n",
    "        pred_boxes = prediction[\"boxes\"].cpu()\n",
    "        pred_scores = prediction[\"scores\"].cpu()\n",
    "        pred_labels = prediction[\"labels\"].cpu()\n",
    "\n",
    "        # Skoru yeterince yüksek kutuları filtrele\n",
    "        keep = pred_scores > 0.3\n",
    "        pred_boxes = pred_boxes[keep]\n",
    "        pred_labels = pred_labels[keep]\n",
    "\n",
    "        # Gerçek görüntü + kutular\n",
    "        axes[i, 0].imshow(img.permute(1, 2, 0).cpu())\n",
    "        axes[i, 0].set_title(\"Gerçek Etiketler\")\n",
    "\n",
    "        # Tahmin edilen görüntü + kutular\n",
    "        axes[i, 1].imshow(img.permute(1, 2, 0).cpu())\n",
    "        axes[i, 1].set_title(\"Tahmin Edilen Kutular (skor > 0.5)\")\n",
    "\n",
    "        # Gerçek kutuları çiz\n",
    "        for box, label in zip(orig_boxes, orig_labels):\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1,\n",
    "                                     edgecolor='g', facecolor='none')\n",
    "            axes[i, 0].add_patch(rect)\n",
    "            axes[i, 0].text(x1, y1, f\"Class: {label.item()}\", color='white',\n",
    "                           bbox=dict(facecolor='g', alpha=0.5))\n",
    "\n",
    "        # Tahmin edilen kutuları çiz\n",
    "        for box, label in zip(pred_boxes, pred_labels):\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1,\n",
    "                                     edgecolor='r', facecolor='none')\n",
    "            axes[i, 1].add_patch(rect)\n",
    "            axes[i, 1].text(x1, y1, f\"Class: {label.item()}\", color='white',\n",
    "                           bbox=dict(facecolor='r', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_visualization.png')\n",
    "plt.close()\n",
    "\n",
    "torch.save(model.state_dict(), \"faster_rcnn_finetuned.pth\")\n",
    "print(\"Model başarıyla kaydedildi!\")\n",
    "print(\"Grafik ve değerlendirmeler kaydedildi!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a18953",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"faster_rcnn_finetuned.pth\")\n",
    "print(\"Model başarıyla kaydedildi!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
